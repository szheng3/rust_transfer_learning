{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 2646, 'val': 294}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# # Transform the data\n",
    "# data_transforms = {\n",
    "#     'train': transforms.Compose([\n",
    "#         transforms.RandomResizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "#     'val': transforms.Compose([\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ]),\n",
    "# }\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "# Load the data using ImageFolder\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "image_dataset = torchvision.datasets.ImageFolder(root='../images_small',\n",
    "                                                 transform=data_transform)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_size = int(0.9 * len(image_dataset))\n",
    "val_size = len(image_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(image_dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for the training and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                           shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "\n",
    "# Set up dict for dataloaders\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "# Store size of training and validation sets\n",
    "dataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n",
    "print(dataset_sizes)\n",
    "# Get class names associated with labels\n",
    "class_names = image_dataset.classes\n",
    "\n",
    "# data_dir = '/Users/shuai/PycharmProjects/Content-Moderation-for-Social-Media/images'\n",
    "# image_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "# class_names = image_datasets['train'].classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the ResNet18 model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze the model parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully-connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "device_name = \"cpu\"\n",
    "# if torch.cuda.is_available():\n",
    "#     device_name = \"cuda:0\"\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device_name = \"mps\"\n",
    "\n",
    "# Move the model to the GPU\n",
    "device = torch.device(device_name)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Decay the learning rate by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Keep track of the best model's performance on the validation set\n",
    "best_acc = 0.0\n",
    "best_model_wts = model.state_dict()\n",
    "\n",
    "# # Start the training loop\n",
    "# for epoch in range(25):\n",
    "#     print('Epoch {}/{}'.format(epoch, 25 - 1))\n",
    "#     print('-' * 10)\n",
    "#\n",
    "#     for phase in ['train', 'val']:\n",
    "#         if phase == 'train':\n",
    "#             scheduler.step()\n",
    "#             model.train()\n",
    "#         else:\n",
    "#             model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda import get_device_name\n",
    "from torch import tensor\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, dataloaders, scheduler, device, num_epochs=25):\n",
    "    model = model.to(device)  # Send model to GPU if available\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Get the input images and labels, and send to GPU if available\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the weight gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass to get outputs and calculate loss\n",
    "                # Track gradient only for training data\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backpropagation to get the gradients with respect to each weight\n",
    "                    # Only if in train\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        # Update the weights\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Convert loss into a scalar and add it to running_loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                # Track number of correct predictions\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # Step along learning rate scheduler when in train\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate and display average loss and accuracy for the epoch\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # print(get_device_name(device))\n",
    "            if device_name == 'mps':\n",
    "                running_corrects = tensor(running_corrects, device='mps', dtype=torch.float32)\n",
    "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # If model performs better on val set, save weights as the best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                # example = torch.rand(1, 3, 224, 224)\n",
    "                # traced_script_module = torch.jit.trace(model, example)\n",
    "                # traced_script_module.save( '../models/best_model_rust.pt')\n",
    "                torch.save(best_model_wts, '../models/best_model.pt')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:3f}'.format(best_acc))\n",
    "\n",
    "    # Load the weights from best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.2017 Acc: 0.9410\n",
      "val Loss: 0.0483 Acc: 0.9966\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.9849\n",
      "val Loss: 0.0278 Acc: 0.9966\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0431 Acc: 0.9894\n",
      "val Loss: 0.0266 Acc: 0.9966\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9909\n",
      "val Loss: 0.0352 Acc: 0.9966\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9906\n",
      "val Loss: 0.0272 Acc: 0.9966\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0289 Acc: 0.9917\n",
      "val Loss: 0.0397 Acc: 0.9864\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0243 Acc: 0.9932\n",
      "val Loss: 0.0316 Acc: 0.9932\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "net = train_model(model, criterion, optimizer, dataloaders, scheduler, device, num_epochs=10)\n",
    "# Convert the best model to Torch Script format\n",
    "# scripted_model = torch.jit.script(net)\n",
    "example = torch.rand(1, 3, 224, 224)\n",
    "scripted_model = torch.jit.trace(net, example)\n",
    "scripted_model.save(\"../models/best_model_scripted.pt\")\n",
    "# Save the Torch Script model\n",
    "# torch.jit.save(net, '../models/best_model_scripted.pt')\n",
    "# net = torch.jit.load('../models/best_model_scripted.pt')\n",
    "# Load the saved state_dict into the model\n",
    "# model.load_state_dict(torch.load('./model/best_model.pt'))\n",
    "# Set the model to evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example = torch.rand(1, 3, 224, 224)\n",
    "scripted_model = torch.jit.trace(net, example)\n",
    "scripted_model.save(\"../models/best_model_scripted.pt\")\n",
    "# Save the Torch Script model\n",
    "# torch.jit.save(net, '../models/best_model_scripted.pt')\n",
    "# net = torch.jit.load('../models/best_model_scripted.pt')\n",
    "# Load the saved state_dict into the model\n",
    "# model.load_state_dict(torch.load('./model/best_model.pt'))\n",
    "# Set the model to evaluation mode\n",
    "# model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Display a batch of predictions\n",
    "def visualize_results(model, dataloader, device):\n",
    "    model = model.to(device)  # Send model to GPU if available\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Get a batch of validation images\n",
    "        images, labels = next(iter(dataloader))\n",
    "        # images = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Get predictions\n",
    "        _, preds = torch.max(model(images), 1)\n",
    "        preds = np.squeeze(preds.cpu().numpy())\n",
    "        images = images.cpu().numpy()\n",
    "\n",
    "    # Plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(40, 10))\n",
    "    for idx in np.arange(len(preds) // 4):\n",
    "        ax = fig.add_subplot(2, len(preds) // 2, idx + 1, xticks=[], yticks=[])\n",
    "        image = images[idx]\n",
    "        image = image.transpose((1, 2, 0))\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(\"{} ({})\".format(class_names[preds[idx]], class_names[labels[idx]]),\n",
    "                     color=(\"green\" if preds[idx] == labels[idx] else \"red\"))\n",
    "    return\n",
    "\n",
    "\n",
    "visualize_results(net, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "# model.eval()\n",
    "# example = torch.rand(1, 3, 224, 224)\n",
    "# traced_script_module = torch.jit.trace(model, example)\n",
    "# traced_script_module.save(\"../models/resnetmodel.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
